const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');

// Configura√ß√£o do pool de conex√µes
const poolConfig = {
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
  max: 10, // m√°ximo de conex√µes no pool
  idleTimeoutMillis: 30000, // tempo limite para conex√µes inativas
  connectionTimeoutMillis: 10000, // tempo limite para novas conex√µes
  statement_timeout: 30000, // tempo limite para statements
  query_timeout: 30000, // tempo limite para queries
  application_name: 'HotBot-Web'
};

// Pool global
let globalPool = null;

// Fun√ß√£o para criar pool de conex√µes
function createPool() {
  if (globalPool) {
    return globalPool;
  }
  
  try {
    globalPool = new Pool(poolConfig);
    
    // Event listeners para o pool
    globalPool.on('connect', (client) => {
      console.log('üîó Nova conex√£o PostgreSQL estabelecida');
    });
    
    globalPool.on('error', (err, client) => {
      console.error('‚ùå Erro no pool PostgreSQL:', err);
    });
    
    globalPool.on('remove', (client) => {
      console.log('üîå Conex√£o PostgreSQL removida do pool');
    });
    
    return globalPool;
  } catch (error) {
    console.error('‚ùå Erro ao criar pool PostgreSQL:', error);
    throw error;
  }
}

// Fun√ß√£o para testar conex√£o b√°sica
async function testDatabaseConnection() {
  let client = null;
  
  try {
    console.log('üîç Testando conex√£o com PostgreSQL...');
    
    // Validar DATABASE_URL
    if (!process.env.DATABASE_URL) {
      throw new Error('DATABASE_URL n√£o est√° definida');
    }
    
    // Criar pool se n√£o existir
    const pool = createPool();
    
    // Testar conex√£o
    client = await pool.connect();
    
    // Testar query simples
    const result = await client.query('SELECT NOW() as timestamp, version() as version');
    const dbInfo = result.rows[0];
    
    console.log('‚úÖ Conex√£o PostgreSQL bem-sucedida');
    console.log('üìÖ Timestamp do banco:', dbInfo.timestamp);
    console.log('üîß Vers√£o PostgreSQL:', dbInfo.version.split(' ')[0]);
    
    return {
      success: true,
      pool: pool,
      timestamp: dbInfo.timestamp,
      version: dbInfo.version,
      connection_string: process.env.DATABASE_URL.replace(/:([^:@]+)@/, ':***@')
    };
    
  } catch (error) {
    console.error('‚ùå Falha na conex√£o PostgreSQL:', error.message);
    
    // Log detalhado do erro
    if (error.code) {
      console.error('üîç C√≥digo do erro:', error.code);
    }
    
    if (error.detail) {
      console.error('üîç Detalhes:', error.detail);
    }
    
    return {
      success: false,
      error: error,
      message: error.message,
      code: error.code || 'UNKNOWN_ERROR'
    };
  } finally {
    if (client) {
      client.release();
    }
  }
}

// Fun√ß√£o para inicializar banco de dados completo
async function initializeDatabase() {
  try {
    console.log('üöÄ Inicializando sistema completo de banco de dados...');
    
    // Testar conex√£o primeiro
    const testResult = await testDatabaseConnection();
    
    if (!testResult.success) {
      throw testResult.error || new Error('Falha no teste de conex√£o');
    }
    
    const pool = testResult.pool;
    
    // Criar tabelas necess√°rias
    await createTables(pool);
    
    // Verificar integridade das tabelas
    await verifyTables(pool);
    
    console.log('‚úÖ Sistema de banco de dados inicializado com sucesso');
    return pool;
    
  } catch (error) {
    console.error('‚ùå Erro na inicializa√ß√£o do banco de dados:', error.message);
    throw error;
  }
}

// Fun√ß√£o para criar tabelas
async function createTables(pool) {
  const client = await pool.connect();
  
  try {
    console.log('üìã Criando/verificando tabelas...');

    // Tabela de tokens
    try {
    await pool.query(`
        CREATE TABLE IF NOT EXISTS tokens (
          id_transacao TEXT PRIMARY KEY,
          token TEXT UNIQUE,
          telegram_id TEXT,
          valor NUMERIC,
          criado_em TIMESTAMP DEFAULT NOW(),
          usado_em TIMESTAMP NULL,
          status TEXT DEFAULT 'pendente',
          usado BOOLEAN DEFAULT FALSE,
          bot_id TEXT,
          utm_source TEXT,
          utm_medium TEXT,
          utm_campaign TEXT,
          utm_term TEXT,
          utm_content TEXT,
          fbp TEXT,
          fbc TEXT,
          ip_criacao TEXT,
          user_agent_criacao TEXT,
          event_time INTEGER
        )
      `);
    await pool.query(`
        CREATE TABLE IF NOT EXISTS tracking_data (
          telegram_id BIGINT PRIMARY KEY,
          fbp TEXT,
          fbc TEXT,
          ip TEXT,
          user_agent TEXT,
          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
      `);
    } catch (err) {
      console.error('‚ùå Erro ao criar tabela tokens:', err.message);
      throw err;
    }
    
    // Garantir coluna criado_em existente
    await pool.query(`
      DO $$
      BEGIN
        IF NOT EXISTS (
          SELECT 1 FROM information_schema.columns
          WHERE table_name='tokens' AND column_name='criado_em'
        ) THEN
          ALTER TABLE tokens ADD COLUMN criado_em TIMESTAMP DEFAULT CURRENT_TIMESTAMP;
        END IF;
        IF NOT EXISTS (
          SELECT 1 FROM information_schema.columns
          WHERE table_name='tokens' AND column_name='fbp'
        ) THEN
          ALTER TABLE tokens ADD COLUMN fbp TEXT;
        END IF;
        IF NOT EXISTS (
          SELECT 1 FROM information_schema.columns
          WHERE table_name='tokens' AND column_name='fbc'
        ) THEN
          ALTER TABLE tokens ADD COLUMN fbc TEXT;
        END IF;
        IF NOT EXISTS (
          SELECT 1 FROM information_schema.columns
          WHERE table_name='tokens' AND column_name='ip_criacao'
        ) THEN
          ALTER TABLE tokens ADD COLUMN ip_criacao TEXT;
        END IF;
        IF NOT EXISTS (
          SELECT 1 FROM information_schema.columns
          WHERE table_name='tokens' AND column_name='user_agent_criacao'
        ) THEN
          ALTER TABLE tokens ADD COLUMN user_agent_criacao TEXT;
        END IF;
      END
      $$;
    `);

    // Criar √≠ndice para status dos tokens
    await pool.query(`
      CREATE INDEX IF NOT EXISTS idx_tokens_status ON tokens(status)
    `);

    // Tabela de downsell progress
    await client.query(`
      CREATE TABLE IF NOT EXISTS downsell_progress (
        telegram_id BIGINT PRIMARY KEY,
        index_downsell INTEGER,
        pagou INTEGER DEFAULT 0,
        criado_em TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);

    // Garantir coluna last_sent_at para controle de envio individual
    await client.query(`
      ALTER TABLE downsell_progress
      ADD COLUMN IF NOT EXISTS last_sent_at TIMESTAMP NULL
    `);

    await client.query(`
      CREATE INDEX IF NOT EXISTS idx_downsell_pagou ON downsell_progress(pagou);
      CREATE INDEX IF NOT EXISTS idx_downsell_criado_em ON downsell_progress(criado_em);
    `);
    
    // Tabela de logs (opcional)
    await client.query(`
      CREATE TABLE IF NOT EXISTS logs (
        id SERIAL PRIMARY KEY,
        level VARCHAR(20) NOT NULL,
        message TEXT NOT NULL,
        meta JSONB NULL,
        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);
    
    // Criar √≠ndice para logs
    await client.query(`
      CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON logs(timestamp);
      CREATE INDEX IF NOT EXISTS idx_logs_level ON logs(level);
    `);
    
    console.log('‚úÖ Tabelas criadas/verificadas com sucesso');
    
  } catch (error) {
    console.error('‚ùå Erro ao criar tabelas:', error.message);
    throw error;
  } finally {
    client.release();
  }
}

// Fun√ß√£o para verificar tabelas
async function verifyTables(pool) {
  const client = await pool.connect();
  
  try {
    console.log('üîç Verificando integridade das tabelas...');
    
    // Verificar estrutura da tabela tokens
    const tokensResult = await client.query(`
      SELECT column_name, data_type, is_nullable 
      FROM information_schema.columns 
      WHERE table_name = 'tokens' 
      ORDER BY ordinal_position
    `);
    
    if (tokensResult.rows.length === 0) {
      throw new Error('Tabela tokens n√£o encontrada');
    }
    
    console.log('‚úÖ Tabela tokens verificada:', tokensResult.rows.length, 'colunas');
    
    // Contar registros existentes
    const countResult = await client.query('SELECT COUNT(*) as total FROM tokens');
    const totalTokens = countResult.rows[0].total;
    
    console.log('üìä Tokens existentes no banco:', totalTokens);
    
    // Verificar tabela logs
    const logsResult = await client.query(`
      SELECT COUNT(*) as total
      FROM information_schema.tables
      WHERE table_name = 'logs'
    `);

    if (logsResult.rows[0].total > 0) {
      console.log('‚úÖ Tabela logs verificada');
    }

    // Verificar tabela downsell_progress
    const downsellResult = await client.query(`
      SELECT COUNT(*) as total
      FROM information_schema.tables
      WHERE table_name = 'downsell_progress'
    `);

    if (downsellResult.rows[0].total > 0) {
      console.log('‚úÖ Tabela downsell_progress verificada');
    }
    
  } catch (error) {
    console.error('‚ùå Erro na verifica√ß√£o das tabelas:', error.message);
    throw error;
  } finally {
    client.release();
  }
}

// Fun√ß√£o de health check
async function healthCheck(pool) {
  if (!pool) {
    return {
      healthy: false,
      error: 'Pool de conex√µes n√£o dispon√≠vel',
      timestamp: new Date().toISOString()
    };
  }
  
  let client = null;
  
  try {
    // Testar conex√£o
    client = await pool.connect();
    
    // Testar query
    const result = await client.query('SELECT NOW() as timestamp, COUNT(*) as connection_count FROM pg_stat_activity');
    const info = result.rows[0];
    
    // Verificar se as tabelas existem
    const tablesResult = await client.query(`
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public' 
      AND table_name IN ('tokens', 'logs')
    `);
    
    const tables = tablesResult.rows.map(row => row.table_name);
    
    return {
      healthy: true,
      timestamp: info.timestamp,
      connection_count: parseInt(info.connection_count),
      tables: tables,
      pool_stats: getPoolStats(pool)
    };
    
  } catch (error) {
    return {
      healthy: false,
      error: error.message,
      timestamp: new Date().toISOString()
    };
  } finally {
    if (client) {
      client.release();
    }
  }
}

// Fun√ß√£o para obter estat√≠sticas do pool
function getPoolStats(pool) {
  if (!pool) {
    return null;
  }
  
  return {
    total_connections: pool.totalCount,
    idle_connections: pool.idleCount,
    waiting_requests: pool.waitingCount,
    max_connections: pool.options.max,
    database: pool.options.database,
    host: pool.options.host,
    port: pool.options.port
  };
}

// Fun√ß√£o para validar ambiente
function validateEnvironment() {
  console.log('üîç Validando ambiente de banco de dados...');
  
  const requiredVars = ['DATABASE_URL'];
  const missingVars = [];
  
  requiredVars.forEach(varName => {
    if (!process.env[varName]) {
      missingVars.push(varName);
    }
  });
  
  if (missingVars.length > 0) {
    console.error('‚ùå Vari√°veis de ambiente obrigat√≥rias n√£o definidas:', missingVars);
    return false;
  }
  
  // Validar formato da DATABASE_URL
  const dbUrl = process.env.DATABASE_URL;
  if (!dbUrl.startsWith('postgresql://') && !dbUrl.startsWith('postgres://')) {
    console.error('‚ùå DATABASE_URL deve come√ßar com postgresql:// ou postgres://');
    return false;
  }
  
  console.log('‚úÖ Ambiente validado com sucesso');
  return true;
}

// Fun√ß√£o de limpeza de emerg√™ncia
function emergencyCleanup() {
  console.log('üßπ Executando limpeza de emerg√™ncia...');
  
  try {
    // Fechar pool global se existir
    if (globalPool) {
      globalPool.end().then(() => {
        console.log('‚úÖ Pool global fechado na limpeza de emerg√™ncia');
      }).catch(err => {
        console.error('‚ùå Erro ao fechar pool na limpeza:', err);
      });
      globalPool = null;
    }
    
    // Limpar vari√°veis de ambiente sens√≠veis do log
    if (process.env.DATABASE_URL) {
      console.log('üîí Vari√°veis sens√≠veis mascaradas para seguran√ßa');
    }
    
    console.log('‚úÖ Limpeza de emerg√™ncia conclu√≠da');
    
  } catch (error) {
    console.error('‚ùå Erro na limpeza de emerg√™ncia:', error);
  }
}

// Fun√ß√£o para executar query segura
async function executeQuery(pool, query, params = []) {
  const client = await pool.connect();
  
  try {
    const result = await client.query(query, params);
    return result;
  } finally {
    client.release();
  }
}

// Fun√ß√£o para executar transa√ß√£o
async function executeTransaction(pool, queries) {
  const client = await pool.connect();
  
  try {
    await client.query('BEGIN');
    
    const results = [];
    for (const { query, params } of queries) {
      const result = await client.query(query, params);
      results.push(result);
    }
    
    await client.query('COMMIT');
    return results;
    
  } catch (error) {
    await client.query('ROLLBACK');
    throw error;
  } finally {
    client.release();
  }
}

// Fun√ß√£o para backup simples
async function createBackup(pool) {
  try {
    const client = await pool.connect();
    
    // Exportar dados da tabela tokens
    const tokensResult = await client.query('SELECT * FROM tokens ORDER BY id');
    const tokens = tokensResult.rows;
    
    // Criar backup em JSON
    const backup = {
      timestamp: new Date().toISOString(),
      version: '1.0',
      tables: {
        tokens: tokens
      }
    };
    
    // Salvar backup
    const backupDir = path.join(__dirname, 'backups');
    if (!fs.existsSync(backupDir)) {
      fs.mkdirSync(backupDir);
    }
    
    const backupFile = path.join(backupDir, `backup_${Date.now()}.json`);
    fs.writeFileSync(backupFile, JSON.stringify(backup, null, 2));
    
    console.log('‚úÖ Backup criado:', backupFile);
    
    client.release();
    return backupFile;
    
  } catch (error) {
    console.error('‚ùå Erro ao criar backup:', error);
    throw error;
  }
}

// Fun√ß√£o para limpar downsells antigos
async function limparDownsellsAntigos(pool) {
  if (!pool) {
    console.warn('‚ö†Ô∏è Pool de conex√µes PostgreSQL n√£o fornecido para limpeza de downsells');
    return;
  }

  try {
    const result = await executeQuery(
      pool,
      `DELETE FROM downsell_progress
       WHERE pagou = 0
       AND criado_em < NOW() - INTERVAL '72 hours'`
    );

    console.log(`üßπ Downsells antigos removidos: ${result.rowCount}`);
  } catch (error) {
    console.error('‚ùå Erro ao limpar downsells antigos:', error.message);
  }
}

// Exportar todas as fun√ß√µes
module.exports = {
  testDatabaseConnection,
  initializeDatabase,
  healthCheck,
  getPoolStats,
  validateEnvironment,
  emergencyCleanup,
  executeQuery,
  executeTransaction,
  createBackup,
  limparDownsellsAntigos,
  createPool,
  createTables,
  verifyTables
};